{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nv6oASw9RYOsObUUMeyuudIw9pkO5l1l",
      "authorship_tag": "ABX9TyNVn6uFdhO0zjhdr5y66AdM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avinash9k5r/python-model-on-words/blob/master/WordModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnGWpwjfl09Z",
        "colab_type": "text"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "Setting up the Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVPMwFh0Z52D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re  # For preprocessing\n",
        "import pandas as pd  # For data handling\n",
        "from time import time # To time our operations\n",
        "from collections import defaultdict #For word frequency\n",
        "import spacy  #For preprocessing\n",
        "import logging # Setting up the loggings to monitor system\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt ='%H:%M:%S',level=logging.INFO)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM3ogeLQmDYb",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1khyfFCraot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IWOTelftf96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-vUiSjPt7JH",
        "colab_type": "code",
        "outputId": "3afe9c6b-8b6f-42d7-f08c-ec10e591de1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "file_id = 'https://drive.google.com/open?id=1EKfQxxUI-WbHWN9yA-Y3z9Da5URA7gHY'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded = drive.CreateFile({'id':'1EKfQxxUI-WbHWN9yA-Y3z9Da5URA7gHY'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('simpsons_dataset.csv')  \n",
        "\n",
        "# Read file as panda dataframe\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"simpsons_dataset.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING - 10:02:08: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 42, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "INFO - 10:02:08: URL being requested: GET https://www.googleapis.com/discovery/v1/apis/drive/v2/rest\n",
            "INFO - 10:02:08: Attempting refresh to obtain initial access_token\n",
            "INFO - 10:02:08: Refreshing access_token\n",
            "INFO - 10:02:08: URL being requested: GET https://www.googleapis.com/drive/v2/files/1EKfQxxUI-WbHWN9yA-Y3z9Da5URA7gHY?alt=json\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKveOR1fmtzs",
        "colab_type": "code",
        "outputId": "caefdd5e-7db6-472c-86f6-22fab594a042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(158314, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNbmd3BtvChW",
        "colab_type": "code",
        "outputId": "94460d26-1660-4047-9fb7-00503cf0e863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>spoken_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>No, actually, it was a little of both. Sometim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Where's Mr. Bergstrom?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>That life is worth living.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Edna Krabappel-Flanders</td>\n",
              "      <td>The polls will be open from now until the end ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        raw_character_text                                       spoken_words\n",
              "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
              "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
              "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
              "3             Lisa Simpson                         That life is worth living.\n",
              "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd7cURvxvGWa",
        "colab_type": "code",
        "outputId": "aa214b9c-ed25-4fba-8f7d-d870bec543c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "df.isnull().sum() # Show missing values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "raw_character_text    17814\n",
              "spoken_words          26459\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fmpJUgEwDnf",
        "colab_type": "text"
      },
      "source": [
        "Removing the missing values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLzbgx2bvKi4",
        "colab_type": "code",
        "outputId": "8679da1d-fcdc-40c8-aecb-d932c33ddbec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "df = df.dropna().reset_index(drop=True)\n",
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "raw_character_text    0\n",
              "spoken_words          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oiwwfj42wRnQ",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLHSWGH2wWLM",
        "colab_type": "text"
      },
      "source": [
        "We are lemmatizing and removing the stopwords and non-alphabetic characters for each line of dialogue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2zW0BBRwa9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en',disable=['ner','parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "def cleaning(doc):\n",
        "    # Lemmatizes and remvoes stopwords\n",
        "    # doc needs to be a spacy Doc object\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
        "    # if a sentence is only one or two words long,\n",
        "    # the benefit for the training is very small\n",
        "    if len(txt) > 2:\n",
        "        return ' '.join(txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gY8REQBwhcF",
        "colab_type": "text"
      },
      "source": [
        "Removes non-alphabetic characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ0fMOH-wfmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['spoken_words'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T36-T2aTwoOY",
        "colab_type": "text"
      },
      "source": [
        "Taking advantage of spaCy.pipe() attribute to speed-up the cleaning process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42yUG3k1wnYW",
        "colab_type": "code",
        "outputId": "7456a87c-30ef-43f3-b783-f0c6d2b87a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = time()\n",
        "\n",
        "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning,batch_size=5000, n_threads=-1)]\n",
        "\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60,2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean up everything: 1.05 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiCRXjBwxaHR",
        "colab_type": "text"
      },
      "source": [
        "Put the results in a DataFrame to remove missing values and duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwUbFUJxwvUv",
        "colab_type": "code",
        "outputId": "aedc84f5-7255-4b71-8d7e-07025101353e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_clean = pd.DataFrame({'clean': txt})\n",
        "df_clean = df_clean.dropna().drop_duplicates()\n",
        "df_clean.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85964, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLJRMCBLxcTH",
        "colab_type": "code",
        "outputId": "5b2290fe-afe6-4559-9325-6ea1e79c06fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_clean.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>actually little disease magazine news show nat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>know sure like talk touch lesson plan teach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>life worth live</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>poll open end recess case decide thought final...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>victory party slide</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               clean\n",
              "0  actually little disease magazine news show nat...\n",
              "2        know sure like talk touch lesson plan teach\n",
              "3                                    life worth live\n",
              "4  poll open end recess case decide thought final...\n",
              "7                                victory party slide"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUwB2009xiPp",
        "colab_type": "text"
      },
      "source": [
        "### Bigrams:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YAgSnvZxgeI",
        "colab_type": "code",
        "outputId": "eb950844-3199-47ed-be00-b735ebfd48c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 07:06:38: 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnvMbZtsxsAV",
        "colab_type": "text"
      },
      "source": [
        "As Phrases() takes a list of list of words as input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcMu4-g_xmy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent = [row.split() for row in df_clean['clean']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZUH8rqmxw66",
        "colab_type": "text"
      },
      "source": [
        "Creates the relevant phrases from the list of sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfa6l54ExuPS",
        "colab_type": "code",
        "outputId": "ab57b3b8-6f52-45c5-f4fc-b829ec12a23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "phrases = Phrases(sent, min_count = 30, progress_per=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 07:06:47: collecting all words and their counts\n",
            "INFO - 07:06:47: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 07:06:47: PROGRESS: at sentence #10000, processed 63561 words and 52816 word types\n",
            "INFO - 07:06:47: PROGRESS: at sentence #20000, processed 130943 words and 99866 word types\n",
            "INFO - 07:06:47: PROGRESS: at sentence #30000, processed 192972 words and 138532 word types\n",
            "INFO - 07:06:47: PROGRESS: at sentence #40000, processed 249842 words and 172659 word types\n",
            "INFO - 07:06:47: PROGRESS: at sentence #50000, processed 311265 words and 208566 word types\n",
            "INFO - 07:06:47: PROGRESS: at sentence #60000, processed 373588 words and 243702 word types\n",
            "INFO - 07:06:47: PROGRESS: at sentence #70000, processed 436441 words and 278740 word types\n",
            "INFO - 07:06:48: PROGRESS: at sentence #80000, processed 497829 words and 311886 word types\n",
            "INFO - 07:06:48: collected 330804 word types from a corpus of 537160 words (unigram + bigrams) and 85964 sentences\n",
            "INFO - 07:06:48: using 330804 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqJHzW9gz_cH",
        "colab_type": "text"
      },
      "source": [
        "The goal of Phraser() is to cut down memory consumption of Phrases(), by discarding model state not strictly needed for the bigram detection task:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7rVms0fyfVd",
        "colab_type": "code",
        "outputId": "0404719e-342d-4205-ca01-ea5036732c3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "bigram = Phraser(phrases)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 07:07:11: source_vocab length 330804\n",
            "INFO - 07:07:14: Phraser built with 126 phrasegrams\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGeQqsAD0ETj",
        "colab_type": "text"
      },
      "source": [
        "Transforms the corpus based on the bigrams detected:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "malvXo_30B0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = bigram[sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MuOuo3f0I4r",
        "colab_type": "text"
      },
      "source": [
        "Most Frequent Words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbnOXEss0HJV",
        "colab_type": "code",
        "outputId": "4635d848-52d4-4ecc-e8a4-1eb5a3f3397c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_freq = defaultdict(int)\n",
        "for sent in sentences:\n",
        "    for i in sent:\n",
        "        word_freq[i] += 1\n",
        "        \n",
        "len(word_freq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vf3D3sy0LtT",
        "colab_type": "code",
        "outputId": "94da9009-d1fe-4bc8-8119-401341ac7d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oh', 'like', 'know', 'get', 'hey', 'think', 'right', 'look', 'want', 'come']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwcPANHL0RbU",
        "colab_type": "text"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMrlIujz0OL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkBwkn1w0UgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cores = multiprocessing.cpu_count() # Count the number of cores in a comuter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsYHlCL90WZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model = Word2Vec(min_count = 20,\n",
        "                     window =2,\n",
        "                     size = 300,\n",
        "                     sample=6e-5,\n",
        "                     alpha=0.03,\n",
        "                     min_alpha = 0.0007,\n",
        "                     negative=20,\n",
        "                     workers=cores-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rpt6Z150abI",
        "colab_type": "text"
      },
      "source": [
        "Building the Vocabulary Table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkGlV3Dl0X9Y",
        "colab_type": "code",
        "outputId": "d0ec2441-6a94-4880-f390-00be6006c2ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=1000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time()-t)/60,2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 07:09:01: collecting all words and their counts\n",
            "INFO - 07:09:01: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #1000, processed 6628 words, keeping 2288 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #2000, processed 12910 words, keeping 3593 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #3000, processed 19216 words, keeping 4611 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #4000, processed 25523 words, keeping 5464 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #5000, processed 32001 words, keeping 6389 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #6000, processed 37928 words, keeping 7128 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #7000, processed 43561 words, keeping 7747 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #8000, processed 49302 words, keeping 8371 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #9000, processed 55282 words, keeping 8966 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #10000, processed 61718 words, keeping 9558 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #11000, processed 68286 words, keeping 10099 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #12000, processed 74903 words, keeping 10598 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #13000, processed 81559 words, keeping 11156 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #14000, processed 87860 words, keeping 11619 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #15000, processed 94369 words, keeping 12119 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #16000, processed 100921 words, keeping 12669 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #17000, processed 107842 words, keeping 13199 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #18000, processed 114658 words, keeping 13709 word types\n",
            "INFO - 07:09:01: PROGRESS: at sentence #19000, processed 121050 words, keeping 14128 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #20000, processed 127351 words, keeping 14506 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #21000, processed 133660 words, keeping 14846 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #22000, processed 140223 words, keeping 15176 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #23000, processed 146270 words, keeping 15503 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #24000, processed 152052 words, keeping 15777 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #25000, processed 158041 words, keeping 16095 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #26000, processed 164090 words, keeping 16389 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #27000, processed 170034 words, keeping 16678 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #28000, processed 175889 words, keeping 16991 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #29000, processed 181726 words, keeping 17257 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #30000, processed 187829 words, keeping 17619 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #31000, processed 193350 words, keeping 17937 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #32000, processed 199047 words, keeping 18251 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #33000, processed 205008 words, keeping 18535 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #34000, processed 210762 words, keeping 18811 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #35000, processed 216190 words, keeping 19062 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #36000, processed 221608 words, keeping 19347 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #37000, processed 227015 words, keeping 19625 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #38000, processed 232477 words, keeping 19886 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #39000, processed 237834 words, keeping 20122 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #40000, processed 243332 words, keeping 20385 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #41000, processed 249016 words, keeping 20596 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #42000, processed 254762 words, keeping 20821 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #43000, processed 260742 words, keeping 21071 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #44000, processed 266751 words, keeping 21346 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #45000, processed 272774 words, keeping 21610 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #46000, processed 278869 words, keeping 21895 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #47000, processed 284797 words, keeping 22087 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #48000, processed 290722 words, keeping 22344 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #49000, processed 297064 words, keeping 22633 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #50000, processed 303182 words, keeping 22878 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #51000, processed 309367 words, keeping 23123 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #52000, processed 315181 words, keeping 23400 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #53000, processed 321442 words, keeping 23622 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #54000, processed 327305 words, keeping 23827 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #55000, processed 333519 words, keeping 24057 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #56000, processed 339552 words, keeping 24264 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #57000, processed 345589 words, keeping 24485 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #58000, processed 351534 words, keeping 24742 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #59000, processed 357580 words, keeping 24988 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #60000, processed 363940 words, keeping 25200 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #61000, processed 369912 words, keeping 25406 word types\n",
            "INFO - 07:09:02: PROGRESS: at sentence #62000, processed 376187 words, keeping 25621 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #63000, processed 382195 words, keeping 25832 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #64000, processed 388444 words, keeping 26056 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #65000, processed 394543 words, keeping 26255 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #66000, processed 400804 words, keeping 26450 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #67000, processed 406707 words, keeping 26672 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #68000, processed 413056 words, keeping 26944 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #69000, processed 419207 words, keeping 27149 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #70000, processed 425408 words, keeping 27401 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #71000, processed 431457 words, keeping 27603 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #72000, processed 437668 words, keeping 27799 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #73000, processed 443689 words, keeping 27969 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #74000, processed 449596 words, keeping 28155 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #75000, processed 455370 words, keeping 28326 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #76000, processed 461226 words, keeping 28492 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #77000, processed 467430 words, keeping 28715 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #78000, processed 473385 words, keeping 28917 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #79000, processed 479401 words, keeping 29107 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #80000, processed 485464 words, keeping 29275 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #81000, processed 491824 words, keeping 29455 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #82000, processed 498249 words, keeping 29557 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #83000, processed 504722 words, keeping 29712 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #84000, processed 511232 words, keeping 29890 word types\n",
            "INFO - 07:09:03: PROGRESS: at sentence #85000, processed 517570 words, keeping 30026 word types\n",
            "INFO - 07:09:03: collected 30178 word types from a corpus of 523700 raw words and 85964 sentences\n",
            "INFO - 07:09:03: Loading a fresh vocabulary\n",
            "INFO - 07:09:03: effective_min_count=20 retains 3319 unique words (10% of original 30178, drops 26859)\n",
            "INFO - 07:09:03: effective_min_count=20 leaves 437324 word corpus (83% of original 523700, drops 86376)\n",
            "INFO - 07:09:03: deleting the raw counts dictionary of 30178 items\n",
            "INFO - 07:09:03: sample=6e-05 downsamples 1200 most-common words\n",
            "INFO - 07:09:03: downsampling leaves estimated 199161 word corpus (45.5% of prior 437324)\n",
            "INFO - 07:09:03: estimated required memory for 3319 words and 300 dimensions: 9625100 bytes\n",
            "INFO - 07:09:03: resetting layer weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.05 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAFJGhfy0hgQ",
        "colab_type": "text"
      },
      "source": [
        "## Training of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Wl-WRX0cnW",
        "colab_type": "code",
        "outputId": "b8d97a8f-ea11-446b-afd3-015bc6914c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "\n",
        "print('Time to train the model: {} mins'.format(round((time()-t)/60,2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING - 07:10:01: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 07:10:01: training model with 1 workers on 3319 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 07:10:02: EPOCH 1 - PROGRESS: at 33.37% examples, 65355 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:03: EPOCH 1 - PROGRESS: at 69.05% examples, 66233 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:04: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:04: EPOCH - 1 : training on 523700 raw words (199218 effective words) took 2.9s, 67847 effective words/s\n",
            "INFO - 07:10:05: EPOCH 2 - PROGRESS: at 33.37% examples, 67333 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:06: EPOCH 2 - PROGRESS: at 70.95% examples, 67781 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:07: EPOCH - 2 : training on 523700 raw words (199222 effective words) took 2.9s, 68703 effective words/s\n",
            "INFO - 07:10:08: EPOCH 3 - PROGRESS: at 33.37% examples, 66263 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:09: EPOCH 3 - PROGRESS: at 70.95% examples, 67367 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:10: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:10: EPOCH - 3 : training on 523700 raw words (199150 effective words) took 2.9s, 68256 effective words/s\n",
            "INFO - 07:10:11: EPOCH 4 - PROGRESS: at 33.37% examples, 67475 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:12: EPOCH 4 - PROGRESS: at 63.30% examples, 61535 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 07:10:13: EPOCH 4 - PROGRESS: at 97.45% examples, 63411 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:13: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:13: EPOCH - 4 : training on 523700 raw words (199540 effective words) took 3.1s, 64156 effective words/s\n",
            "INFO - 07:10:14: EPOCH 5 - PROGRESS: at 33.37% examples, 67613 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:15: EPOCH 5 - PROGRESS: at 70.95% examples, 67832 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:16: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:16: EPOCH - 5 : training on 523700 raw words (199462 effective words) took 2.9s, 68336 effective words/s\n",
            "INFO - 07:10:17: EPOCH 6 - PROGRESS: at 33.37% examples, 66728 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:18: EPOCH 6 - PROGRESS: at 69.05% examples, 67414 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:19: EPOCH - 6 : training on 523700 raw words (199000 effective words) took 3.0s, 67437 effective words/s\n",
            "INFO - 07:10:20: EPOCH 7 - PROGRESS: at 33.37% examples, 67061 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:21: EPOCH 7 - PROGRESS: at 69.05% examples, 67242 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:22: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:22: EPOCH - 7 : training on 523700 raw words (199266 effective words) took 2.9s, 68925 effective words/s\n",
            "INFO - 07:10:23: EPOCH 8 - PROGRESS: at 33.37% examples, 65413 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:24: EPOCH 8 - PROGRESS: at 70.95% examples, 67531 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:25: EPOCH - 8 : training on 523700 raw words (199201 effective words) took 3.0s, 65485 effective words/s\n",
            "INFO - 07:10:26: EPOCH 9 - PROGRESS: at 33.37% examples, 66689 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:27: EPOCH 9 - PROGRESS: at 69.05% examples, 66789 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:28: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:28: EPOCH - 9 : training on 523700 raw words (199075 effective words) took 2.9s, 68398 effective words/s\n",
            "INFO - 07:10:29: EPOCH 10 - PROGRESS: at 33.37% examples, 66801 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:30: EPOCH 10 - PROGRESS: at 69.05% examples, 67532 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:31: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:31: EPOCH - 10 : training on 523700 raw words (199385 effective words) took 2.9s, 68123 effective words/s\n",
            "INFO - 07:10:32: EPOCH 11 - PROGRESS: at 33.37% examples, 67433 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:33: EPOCH 11 - PROGRESS: at 69.05% examples, 67679 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:34: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:34: EPOCH - 11 : training on 523700 raw words (198819 effective words) took 2.9s, 69284 effective words/s\n",
            "INFO - 07:10:35: EPOCH 12 - PROGRESS: at 33.37% examples, 67424 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:36: EPOCH 12 - PROGRESS: at 70.95% examples, 68914 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:37: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:37: EPOCH - 12 : training on 523700 raw words (199107 effective words) took 3.0s, 66452 effective words/s\n",
            "INFO - 07:10:38: EPOCH 13 - PROGRESS: at 33.37% examples, 67649 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:39: EPOCH 13 - PROGRESS: at 70.95% examples, 68706 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:39: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:39: EPOCH - 13 : training on 523700 raw words (199018 effective words) took 2.9s, 69241 effective words/s\n",
            "INFO - 07:10:41: EPOCH 14 - PROGRESS: at 35.34% examples, 68485 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:42: EPOCH 14 - PROGRESS: at 72.83% examples, 69251 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:42: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:42: EPOCH - 14 : training on 523700 raw words (199635 effective words) took 2.9s, 69824 effective words/s\n",
            "INFO - 07:10:43: EPOCH 15 - PROGRESS: at 33.37% examples, 67115 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:44: EPOCH 15 - PROGRESS: at 70.95% examples, 68001 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:45: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:45: EPOCH - 15 : training on 523700 raw words (199205 effective words) took 2.9s, 69541 effective words/s\n",
            "INFO - 07:10:46: EPOCH 16 - PROGRESS: at 35.34% examples, 66448 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:47: EPOCH 16 - PROGRESS: at 72.83% examples, 68622 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:48: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:48: EPOCH - 16 : training on 523700 raw words (199196 effective words) took 3.0s, 66846 effective words/s\n",
            "INFO - 07:10:49: EPOCH 17 - PROGRESS: at 33.37% examples, 66354 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:50: EPOCH 17 - PROGRESS: at 70.95% examples, 68108 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:51: EPOCH - 17 : training on 523700 raw words (199097 effective words) took 2.9s, 69022 effective words/s\n",
            "INFO - 07:10:52: EPOCH 18 - PROGRESS: at 35.34% examples, 68079 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:53: EPOCH 18 - PROGRESS: at 72.83% examples, 69105 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:54: EPOCH - 18 : training on 523700 raw words (199697 effective words) took 2.9s, 69799 effective words/s\n",
            "INFO - 07:10:55: EPOCH 19 - PROGRESS: at 33.37% examples, 66141 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:56: EPOCH 19 - PROGRESS: at 70.95% examples, 67768 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:57: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:10:57: EPOCH - 19 : training on 523700 raw words (199491 effective words) took 2.9s, 68492 effective words/s\n",
            "INFO - 07:10:58: EPOCH 20 - PROGRESS: at 33.37% examples, 67127 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:10:59: EPOCH 20 - PROGRESS: at 70.95% examples, 68825 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:00: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:00: EPOCH - 20 : training on 523700 raw words (198582 effective words) took 2.9s, 69552 effective words/s\n",
            "INFO - 07:11:01: EPOCH 21 - PROGRESS: at 29.42% examples, 57749 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:02: EPOCH 21 - PROGRESS: at 67.17% examples, 64243 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:03: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:03: EPOCH - 21 : training on 523700 raw words (199255 effective words) took 3.0s, 66004 effective words/s\n",
            "INFO - 07:11:04: EPOCH 22 - PROGRESS: at 35.34% examples, 67687 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:05: EPOCH 22 - PROGRESS: at 72.83% examples, 68298 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:06: EPOCH - 22 : training on 523700 raw words (199012 effective words) took 2.9s, 69210 effective words/s\n",
            "INFO - 07:11:07: EPOCH 23 - PROGRESS: at 35.34% examples, 67710 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:08: EPOCH 23 - PROGRESS: at 72.83% examples, 68839 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:09: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:09: EPOCH - 23 : training on 523700 raw words (198827 effective words) took 2.9s, 69565 effective words/s\n",
            "INFO - 07:11:10: EPOCH 24 - PROGRESS: at 33.37% examples, 67056 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:11: EPOCH 24 - PROGRESS: at 70.95% examples, 67549 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:11: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:11: EPOCH - 24 : training on 523700 raw words (199315 effective words) took 2.9s, 68632 effective words/s\n",
            "INFO - 07:11:13: EPOCH 25 - PROGRESS: at 35.34% examples, 68109 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:14: EPOCH 25 - PROGRESS: at 67.17% examples, 64378 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:14: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:14: EPOCH - 25 : training on 523700 raw words (199170 effective words) took 3.0s, 66272 effective words/s\n",
            "INFO - 07:11:16: EPOCH 26 - PROGRESS: at 33.37% examples, 65145 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 07:11:17: EPOCH 26 - PROGRESS: at 70.95% examples, 67011 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:17: EPOCH - 26 : training on 523700 raw words (199503 effective words) took 2.9s, 67971 effective words/s\n",
            "INFO - 07:11:18: EPOCH 27 - PROGRESS: at 33.37% examples, 66150 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:19: EPOCH 27 - PROGRESS: at 69.05% examples, 67285 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:20: EPOCH - 27 : training on 523700 raw words (199304 effective words) took 2.9s, 68653 effective words/s\n",
            "INFO - 07:11:21: EPOCH 28 - PROGRESS: at 33.37% examples, 67400 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:22: EPOCH 28 - PROGRESS: at 70.95% examples, 68291 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:23: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:23: EPOCH - 28 : training on 523700 raw words (199329 effective words) took 2.9s, 68656 effective words/s\n",
            "INFO - 07:11:24: EPOCH 29 - PROGRESS: at 33.37% examples, 66838 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:25: EPOCH 29 - PROGRESS: at 67.17% examples, 64015 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:26: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:26: EPOCH - 29 : training on 523700 raw words (198902 effective words) took 3.0s, 65618 effective words/s\n",
            "INFO - 07:11:27: EPOCH 30 - PROGRESS: at 33.37% examples, 66990 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:28: EPOCH 30 - PROGRESS: at 70.95% examples, 68001 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 07:11:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 07:11:29: EPOCH - 30 : training on 523700 raw words (199000 effective words) took 2.9s, 68816 effective words/s\n",
            "INFO - 07:11:29: training on a 15711000 raw words (5975983 effective words) took 88.1s, 67832 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to train the model: 1.47 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWW0Ghuz1DfT",
        "colab_type": "text"
      },
      "source": [
        "# Exploring the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRjyKV1f1Hfj",
        "colab_type": "text"
      },
      "source": [
        "Most Similar to:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXT2xaqj0mpL",
        "colab_type": "code",
        "outputId": "33e025e7-33d1-4b16-c974-c2d25815e0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"homer\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 07:12:11: precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bongo', 0.7438229322433472),\n",
              " ('marge', 0.7383730411529541),\n",
              " ('wife', 0.729287326335907),\n",
              " ('rude', 0.728277862071991),\n",
              " ('snuggle', 0.7205110788345337),\n",
              " ('sorry', 0.7020863890647888),\n",
              " ('listen', 0.7008452415466309),\n",
              " ('crummy', 0.6998229026794434),\n",
              " ('gee', 0.6980044841766357),\n",
              " ('attract', 0.696446418762207)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2dEF_9b1Kix",
        "colab_type": "code",
        "outputId": "497ece55-6575-4348-a15f-80c64b9b4b96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"homer_simpson\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('congratulation', 0.7384845018386841),\n",
              " ('easily', 0.7243740558624268),\n",
              " ('council', 0.7230184674263),\n",
              " ('recent', 0.7135732769966125),\n",
              " ('waylon', 0.7095463275909424),\n",
              " ('governor', 0.7063230276107788),\n",
              " ('pleased', 0.6944870948791504),\n",
              " ('kennedy', 0.6925977468490601),\n",
              " ('committee', 0.6886483430862427),\n",
              " ('defeat', 0.6862305998802185)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeYeCi6G1T2I",
        "colab_type": "code",
        "outputId": "0635e01f-75ca-4429-d3bf-c624d1dbff42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"marge\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('convince', 0.753345251083374),\n",
              " ('sorry', 0.7442652583122253),\n",
              " ('hammock', 0.738720178604126),\n",
              " ('homer', 0.7383730411529541),\n",
              " ('rude', 0.731797456741333),\n",
              " ('grownup', 0.7308133840560913),\n",
              " ('becky', 0.723953127861023),\n",
              " ('arrange', 0.7207881212234497),\n",
              " ('raccoon', 0.7200326919555664),\n",
              " ('loving', 0.7158425450325012)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCv2No6f1Z35",
        "colab_type": "code",
        "outputId": "25fc529b-e2bb-45b7-b509-5cc5064f73c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"bart\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lisa', 0.8213196992874146),\n",
              " ('homework', 0.7795455455780029),\n",
              " ('mom', 0.7676389813423157),\n",
              " ('substitute', 0.763089656829834),\n",
              " ('convince', 0.7581101655960083),\n",
              " ('surprised', 0.7539457082748413),\n",
              " ('hearing', 0.7440679669380188),\n",
              " ('strangle', 0.7392697334289551),\n",
              " ('upset', 0.737227201461792),\n",
              " ('impressive', 0.7352877855300903)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9Vx-TPU1kWZ",
        "colab_type": "text"
      },
      "source": [
        "Similarities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scUVLaWC1fkm",
        "colab_type": "code",
        "outputId": "2af1bc0c-0674-4a99-fe7e-89cda7f75b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "w2v_model.wv.similarity('maggie', 'tavern')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23141363"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfUlPuqE1mQc",
        "colab_type": "code",
        "outputId": "fdbb1ff1-e72a-4e2e-ee51-486d85732194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "w2v_model.wv.similarity('maggie','baby')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.69330287"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "batVLRix1q3p",
        "colab_type": "code",
        "outputId": "9de1e191-00d5-46e1-971b-07106b3c9fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "w2v_model.wv.similarity('bart','nelson')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6432154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkzYDJiP2CQv",
        "colab_type": "text"
      },
      "source": [
        "Odd-One-Out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6le0i47H2BCG",
        "colab_type": "code",
        "outputId": "8c86b21f-6e24-4388-e9fd-f1617648fb2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "w2v_model.wv.doesnt_match(['jimbo','milhouse','kearney'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING - 07:16:06: vectors for words {'kearney'} are not present in the model, ignoring these words\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jimbo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSwxrbV2177x",
        "colab_type": "code",
        "outputId": "38b285ad-d5ee-4a2c-9d36-63e317cb71a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "w2v_model.wv.doesnt_match([\"nelson\",\"bart\",\"milhouse\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nelson'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SepgxXhF2JSa",
        "colab_type": "code",
        "outputId": "214a60d6-d168-4656-d879-27ac4a91c5a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "w2v_model.wv.doesnt_match(['homer','patty','selma'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'homer'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QVeH1XR2P9v",
        "colab_type": "text"
      },
      "source": [
        "Analogy Difference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n-jJtRv2MTD",
        "colab_type": "code",
        "outputId": "e519fc6e-cce4-46a8-b109-b62414ca9d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"woman\",\"homer\"],negative=[\"marge\"],topn=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('admire', 0.6310784816741943),\n",
              " ('obvious', 0.5805646181106567),\n",
              " ('carefully', 0.5758380889892578)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itjH5Rat2SKX",
        "colab_type": "code",
        "outputId": "f52d56e0-5c62-432f-cea9-f863d9380732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"woman\",\"bart\"],negative=[\"man\"],topn=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lisa', 0.7217448949813843),\n",
              " ('parent', 0.7040499448776245),\n",
              " ('upset', 0.6835949420928955)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5mtiFWh2XN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}